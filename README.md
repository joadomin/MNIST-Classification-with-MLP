This is just a simple experiment of classification of the MINST dataset with MLP of 3 and 4 hidden layers.
First, we analyse different configurations and choose the best one after a short training.
Then, a long training is performed with an adequeate learning_rate choice.

The file mynotebook.ipynb contains all the information and there is no need to do the training because the saved models are in the repository.
